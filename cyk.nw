\title{Automatic execution of the CYK algorithm}
\author{by Simon Gustavs, Lukas Petermann and Undine Holst}

\section{Introduction}
The CYK algorithm was created by John Cocke, Daniel Younger and Tadao Kasami to determine wether 
a word is part of a particular context free grammar or not. The grammar needs to be in Chomsky normal 
form(CNF) to be tested by the CYK algorithm. Therefore the first thing happening after the user enters the 
grammar and the word is the transformation of the grammar into CNF. After that the CYK algorithm can be 
executed and the result will be put into a latex file.

\section{Usage}
To use the program the program main.py must be executed via an IDE, editor or the command line using the 
command 'python3 main.py'.Then the grammar members need to be imported from an external file or defined in the command line using the following syntax:
\newline
\newline Symbols are represented by upper case letters and they are divided by commas, semicolons, spaces, dots or pipes. 
For the output the symbols will be framed by curly brackets. 
\newline E.g.: In: 'A,B,C' Out: '\{A,B,C\}'
\newline	Terminal Symbols are represented by lower case letters and are put in and out the same way as symbols.
\newline E.g.: In: 'a,b,c' Out: '\{a,b,c\}'
\newline	For each Symbol (e.g. A) there will be rules required. Those are also divided by commas. 
\newline E.g.: If A can be turned into B, a or epsilon: In: A: 'B, a, \textbackslash E' Out: '\{A -$>$ B;a;\E\}'
\newline	The starting symbol has to be one of the symbols(upper case). 
And note that epsilon has to be written as '\textbackslash E'.
\newline
\newline If the input is realized through an external file that file needs to be structured as follows:
\newline Empty lines will be ignored by the program.
\newline The first filed line needs to contain all variables represented by upper case letters divided by any of the allowed splitting symbols. 
\newline The second filled line needs to contain the alphabet represented by lower case letters also divided by any of the allowed splitting symbols.
\newline The third filled line has to contain the starting symbol which must be part of the variables.
\newline The following non-empty lines must contain the rules for each variable. The first character of the lines for the rules needs to be the variable for that 
the rules of this line apply. For better clarity next an arrow like this '-$>$' may be used to differentiate between the key variable and the rules. Then the rules need 
to be stated using the already known splitting symbols.
\newline A file could look like this:
\newline
\newline 1 S,A,B
\newline 2 a,b
\newline 3
\newline 4 S
\newline 5 S -$>$ AA,AB
\newline 6 A -$>$ BA, a
\newline 7 B -$>$ b
\newline
\newline Next the word that the user wants to analyze will be asked for. Afterwards the program will be executed and the user
 needs to press enter time and time again until the program is done.
Now the file CYK\_Tableau.pdf shows the cyk building table and the cnf of the grammar if opened.

\newpage
\section{Main}

In the main program all other important parts of the program are executed.
<<main>>=
/*
	<<eingabe>>
	<<cyk>>
	<<tabular>>
	<<cnf>>
	<<cnftest>>
	<<runpdflatex>>
	<<input>>
	<<chomskynf>>
	<<execcyk>>
*/

"""run this file"""
import subprocess
import eingabe
import cyk
import tabular
import cnf
import cnf_test

@
First the needed files are imported. Then a function to call the subprocess for carrying out the converting of the the latex
 file into a pdf file is defined.
 
<<runpdflatex>>=
def run_pdflatex(file_name='CYK_Tableau.tex', path='.'):
    """ cnonvert tex file to pdf"""
    return subprocess.call(['pdflatex', file_name], cwd=path)

@
Afterwards the input of all necessary information about the grammar and the word in question is carried out. The grammar may
 be imported so that possibility is given through a yes/no decision.
 
<<input>>=
grammar = eingabe.CFG()			# eingabe.cfg.new_grammar(grammar)
if input("Do you want to import your Grammar? [y/N] ") in ['Y', 'y']:
    eingabe.CFG.file_input(grammar)
else:
	 eingabe.CFG.new_grammar(grammar)
word = eingabe.new_word()
#cnf_test.print_grammar(grammar.rules)
#grammar.rules = dict(S={'aACa'}, A={'B', 'a'}, B={'C', 'c'}, 
#			C={'cC', r'\E'})
#grammar.start = 'S'
#grammar.alphabet = {'a', 'b', 'c'}
#grammar.variables = set(key for key in grammar.rules)

@
Then the routine for converting the grammar into CNF is called. While converting there will be intermediate outputs. Therefore
 after the routine is done, there will be a success message and the converted grammar will be printed.
 
<<chomskynf>>=
grammar.rules = cnf.cnf(grammar) # bring CFG in Chomsky NF
print("cnf done")
cnf_test.print_grammar(grammar.rules)

@
After all the preparations are done, the CYK algorithm is executed and the result is stored in a table.
Then a function to convert that table, the grammar and the word in question into a latex text is called.
The latex file is opened, the text is written into it and it is closed again. Then a success message is printed.
 Lastly the latex file is turned into a pdf file using the run\_ pdflatex function and again a success message is printed.
 
<<execcyk>>=
table = cyk.cyk(grammar, word)  		# run CYK algorithm
tableau = tabular.to_latex(table, word, grammar.start, grammar.rules)
file = open(file="CYK_Tableau.tex", mode="w")
file.write(tableau)
file.close()
print('\nwritten in CYK_Tableau.tex')
run_pdflatex()
print('\noutput saved to CYK_Tableau.pdf')

@
\section{Input}
Through the input a context free grammar and a word to be tested of being part of the grammar are entered. 
First of all a list with splitting symbols is defined in order to be able to differentiate different symbols.

<<eingabe>>=
/*
	<<newword>>
	<<cfg>>
	<<csvar>>
	<<csyntax>>
*/

"""define input of CFG"""
splitter = ['.', ';', '  ', ',', '|']

@
Next the input of the word in question is realized. In order to test the word later the string from the input is converted 
into a character list.

<<newword>>=
def new_word():
    """get word from user"""
    word = input("Please enter the word. \n")
    char_list = []
    for i in word:
        char_list.append(i)
    return char_list

@
A context free grammar consists of variables, an alphabet, a set of rules and a start variable. Therefore a class for context
 free grammars (CFG) is defined.
 
<<cfg>>=
/*
	<<initcfg>>
	<<ngrammar>>
	<<filein>>
*/
class CFG:
    """Definition of context-free Grammar"""
@
The members of a context free grammar (variables, the alphabet, the rules and the start variable) are defined as follows:
 
<<initcfg>>=

    def __init__(self):
        self.variables = []
        self.alphabet = []
        self.rules = dict(set())
        self.start = None

    def set_variables(self, variables):
        """set variables"""
        self.variables = variables

    def set_alphabet(self, alphabet):
        """set alphabet"""
        self.alphabet = alphabet

    def set_rules(self, key, value):
        """set rules"""
        if key not in self.rules:
            self.rules.update({key: set()})
        self.rules[key].add(value)

    def set_start(self, start):
        """set starting symbol"""
        self.start = start

@
Following these definitions the user input via command line is implemented.
First the user is asked to enter all variables respectively symbols and then all splitting symbols in the string are replaced 
by space. The string is then converted into a list by turning the string parts, divided by space, into list members. 
Afterwards that list is assigned as the variables of the grammar. Then the terminal symbols 
respectively the alphabet are inquired from the user. After replacing all splitting symbols with space the string is turned into a list again and 
assigned as the alphabet of the grammar. The rules for each variable are then inquired from the user. After replacing the 
splitting symbols with space and turning the string into a list, the function for checking the syntax is called. If the syntax is fine the sets of keys and
 values are assigned as the rules of the grammar. After that the start variable is inquired from the user and is tested to 
 be part of the variables.

<<ngrammar>>=

    def new_grammar(self):
        """get grammar from user input"""
        var = input("Please enter all symbols.\n")
        for i in splitter:
            var = var.replace(i, ' ')
        self.set_variables(var.split())

        var = input("Please enter all terminal symbols.\n")
        for i in splitter:
            var = var.replace(i, ' ')
        self.set_alphabet(var.split())

        for i in self.variables:
            var = input(
                "Please enter all rules for " + i +
                ".\nPlease enter \\E for epsilon (if needed).\n")
            for k in splitter:
                var = var.replace(k, ' ')
            var = var.split()
            check_syntax(self.variables, self.alphabet, var)
            for k in var:
                self.set_rules(i, k)

        self.set_start(input("Please enter the starting Symbol.\n"))
        check_start(self.variables, self.start)

@
Since there is also the option to enter the grammar via an external file, that file needs to be converted into usable information 
for the grammar. First the user is asked to enter the filename they want to import. That file is then split into a list of 
all lines from which the empty lines are removed. The splitting symbols in the first two lines are replaced by spaces. Then 
the first line is assigned as the variables and the second line as the alphabet. The start variable from the third line is 
then checked to be part of the variables. Next the first three lines of the file will be deleted so just the rules of the 
grammar will be left in the file. Then the 

<<filein>>=

def file_input(self):
        
  file = open(input("Enter filename you want to import.\n"), "r").read().splitlines()
  #Remove Empty Lines from the list
  for i in file:
     if i == '':
     file.remove(i)
  #Extract the Terminal Symbols and the Alphabet from the file
  for i in splitter:
     file[0] = file[0].replace(i, ' ')
     file[1] = file[1].replace(i, ' ')
  self.set_variables(file[0].split())
  self.set_alphabet(file[1].split())

  self.set_start(file[2])
  check_start(self.variables, self.start)
  #delete the first three Elements from the List
  #(Variables, Alphabet and Starting Symbol)
  del file[0:3]

  for rules in file:
      terminal = rules[0]
      for i in splitter:
          rules = rules.replace(i, ' ')
      rules = rules.split()
      del rules[0]
      rules.remove('->')
      check_syntax(self.variables, self.alphabet, rules)
      for k in rules:
          self.set_rules(terminal, k)

@
The syntax of the grammar needs to be checked for the program to work. Therefore the variables from the input are divided 
into upper and lower case variables. Then for each lower and upper case variable it is checked whether they are part of the 
alphabet or the variables. If not then an error message will be displayed.

<<csyntax>>=
def check_syntax(variables, alphabet, rules):
    """check input syntax"""
    lower = []
    upper = []
    for i in rules:
        if i != r'\E':
            for j in i:
                if j.islower():
                    lower.append(j)
                if j.isupper():
                    upper.append(j)

    for low in lower:
        if low not in alphabet:
            print("Inappropriate terminal symbols have been entered.\n")
            raise SystemExit

    for upp in upper:
        if upp not in variables:
            print("Inappropriate symbols have been entered. \n")
            raise SystemExit

@
The start variable also needs to be checked of being part of the variables. If it is not, an error message is shown again.

<<csvar>>=
def check_start(variables, start):
    """check if starting symbol is in grammar"""
    if start not in variables:
        print("The starting Symbol has to be part of the symbols. \n")
		  raise SystemExit

@
\section{Chomsky Normal Form}
As mentioned in the introduction, before applying the CYK algorithm the grammar needs to be converted into
Chomsky Normal Form. Therefore 

<<cnf>>=

"""functions to bring grammar into CNF"""
import string
import cnf_test
import cyk
import cnf_alternative


def cnf(grammar):
    """sequentially call distinct functions"""
    grammar.rules = epsilon_elim(grammar.start, grammar.rules)
    print("Occurrences of epsilon eliminated.")
    cnf_test.print_grammar(grammar.rules)
    grammar.rules = chain_elim(grammar.rules)
    print("Occurrences of chained rules eliminated.")
    cnf_test.print_grammar(grammar.rules)
    grammar_alternative = non_iso_term_elim(grammar.rules, grammar.variables, grammar.alphabet)
    print("Occurrences of non isolated terminal symbols eliminated.")
    cnf_test.print_grammar(grammar_alternative[0])
    if grammar_alternative[1]:
        grammar_alternative = cnf_alternative.long_right_alternative(grammar_alternative[0])
        print("Occurrences of long right sides eliminated.")
        return grammar_alternative
    grammar.rules = long_right_elim(grammar_alternative[0], grammar.alphabet)
    print("Occurrences of long right sides eliminated.")
    cnf_test.print_grammar(grammar.rules)
    return grammar.rules


def epsilon_elim(start, rules):
    """eliminate epsilon"""
    eps = r'\E'
    eps_keys = cyk.check_rule(rules, eps)  # find occurrences of epsilon in rules
    if not eps_keys:
        return rules
    for key, value in rules.items():
        tmp_key = set()
        tmp_rule = set()
        for val in value:
            # get keys to remove from tmp_key
            tmp_key.update(char for char in eps_keys if char in val)
            tmp_rule.update(val.replace(char, "") for char in tmp_key for val in value if
                            char in val)  # create rules by removing characters
        value.update(tmp_rule)
    for key, values in rules.items():  # replace empty sets with epsilon
        tmpval = values.copy()
        for word in values:
            if not word:
                tmpval.add(eps)
                tmpval.remove('')
        rules[key] = tmpval
    for key in eps_keys:
        rules[key].remove(r'\E')
    eps_keys = cyk.check_rule(rules, eps)
    if len(eps_keys) > 1 or not (len(eps_keys) == 1 and start in eps_keys):
        return epsilon_elim(start, rules)

    return rules


def chain_elim(rules):
    """eliminate chained rules"""
    keys = []
    for key in rules.keys():
        keys.append(key)
    new_dict = {}
    for key in list(keys):
        new_dict.update({key: rules[key]})
        new_keys = cyk.check_rule(rules, key)  # get vars that point to singular variables
        for k in new_keys:  # substitute rules of V on rhs with V itself
            rules[k].update(rules[key])
            rules[k].remove(key)
    return new_dict


# search rules for non-isolated terminal symbols (e.g. in the form of 'aa' or 'aA'...)
def non_iso_term_elim(rules, variables, alphabet):
    """eliminate non isolated terminal symbols"""
    alph = set(string.ascii_uppercase) - set(variables)
    new_dict = dict()
    if len(alphabet) > len(alph):
        return cnf_alternative.non_iso_term_elim_alternative(rules, variables, alphabet)
    map_term_not_term = [(char, symbol) for char, symbol
                         in zip(alphabet, alph)]
    for keys, values in rules.items():
        new_dict[keys] = set()
        tmp_val = values.copy()  # save temporary copy of values
        for val in tmp_val:  # iterate over set of strings
            tmp_str = val
            # substitute new variable with every occurrence of terminal symbol..
            for term in map_term_not_term:
                # if the terminal symbol is not isolated
                if term[0] in tmp_str and len(tmp_str) > 1:
                    tmp_str = tmp_str.replace(term[0], term[1])
                    new_dict[term[1]] = set(term[0])
            tmp_val.remove(val)
            tmp_val.add(tmp_str)

        new_dict[keys].update(tmp_val)
    for value in new_dict.values():  # make sure it worked, reiterate if needed
        for strings in value:
            if len(strings) > 1:
                for term in alphabet:
                    if term in strings:
                        non_iso_term_elim(new_dict,
                                          (key for key, values in new_dict.items()),
                                          alphabet)
    return new_dict, False


def long_right_elim(rules, alphabet):
    """eliminate long right sides"""
    alph = set(string.ascii_uppercase) - set(key for key in rules)
    if len(alphabet) > len(alph):
        return cnf_alternative.long_right_alternative(rules)
    new_dict = dict()
    for key, values in rules.items():
        tmp_val = values.copy()
        new_dict[key] = tmp_val
        for strings in values:
            if len(strings) > 2:
                tmp_str = strings
                new_val = tmp_str[-2:]  # ABC -> A BC (split last two vars)
                new_key = alph.pop()  # new variable X
                tmp_str = tmp_str[:-2] + new_key  # updated rule AX
                new_dict[key].remove(strings)
                new_dict[key].add(tmp_str)
                new_dict[new_key] = set()
                new_dict[new_key].add(new_val)  # new rule: X -> BC
    repeat = False
    for key, values in new_dict.items():  # not pretty i know. if needed, reiterate
        for strings in values:
            if len(strings) > 2:
                repeat = True
    if repeat:
        return long_right_elim(new_dict, alphabet)
    return new_dict